{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7c3a87-dd1d-47de-a29e-0e42e5143567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import lru_cache, partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.time_feature import get_lags_for_frequency\n",
    "from pandas.core.arrays.period import period_array\n",
    "from transformers import InformerConfig, InformerForPrediction\n",
    "from transformers import PretrainedConfig\n",
    "from typing import Optional\n",
    "\n",
    "from gluonts.transform.sampler import InstanceSampler\n",
    "\n",
    "\n",
    "from gluonts.time_feature import TimeFeature\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.transform import (\n",
    "    AddAgeFeature,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    AsNumpyArray,\n",
    "    Chain,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    InstanceSplitter,\n",
    "    RemoveFields,\n",
    "    SelectFields,\n",
    "    SetField,\n",
    "    TestSplitSampler,\n",
    "    Transformation,\n",
    "    ValidationSplitSampler,\n",
    "    VstackFeatures,\n",
    "    RenameFields,\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from torch.optim import AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01245d6e-567c-483f-be0c-881c6cf22359",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_dataset = load_dataset(\"shaddie/thrust_curves_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af4db824-0b8c-4ffe-9dde-081e11ff6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pad_max(dataset):\n",
    "    l=len(dataset)\n",
    "    m = 0\n",
    "    for r in range(l):\n",
    "        # real = tc_dataset[split][r]['feat_dynamic_real']\n",
    "        target = dataset[r]['target']\n",
    "        if m < len(target):\n",
    "            m = len(target)\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def pad_data(data, m, split):\n",
    "    l=len(data)\n",
    "    tc = []\n",
    "    for r in range(l):\n",
    "        real = data[r]['feat_dynamic_real']\n",
    "        target = data[r]['target']\n",
    "        rlen = len(real)\n",
    "        pad = [0 for _ in range(61-rlen)]\n",
    "        # target = tc_dataset['train'][r]['target']\n",
    "        real = real + pad\n",
    "        target = target + pad\n",
    "        tc.append({\n",
    "            'start': data[r]['start'],\n",
    "            'target': target,\n",
    "            'feat_static_cat': data[r]['feat_static_cat'],\n",
    "            'feat_dynamic_real': real,\n",
    "            'item_id': data[r]['item_id']\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    return tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f5c9dda-f4c0-4a89-bc83-8c394bdd34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "m = find_pad_max(tc_dataset[\"train\"])\n",
    "split=\"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29b91cee-d666-4ffe-815d-f425952b762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = pad_data(tc_dataset[split], m=m, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb065aac-b0f6-4614-8657-39fcee289f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=Dataset.from_list(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5acf98c-297d-4029-ad49-832e360b31a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'],\n",
       "    num_rows: 266\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0c1b70b-578a-424f-a1fa-0483a03808f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1W\"\n",
    "prediction_length = 8\n",
    "\n",
    "# assert len(train_example[\"target\"]) + prediction_length == len(\n",
    "#     dataset[\"validation\"][0][\"target\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "414f227c-4179-4070-8120-f1d6ad693f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example =train_dataset[0]\n",
    "train_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16841c07-bacd-409a-8256-264f809bc167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_of_samples = 150\n",
    "\n",
    "figure, axes = plt.subplots()\n",
    "axes.plot(train_example[\"target\"][-num_of_samples:], \n",
    "          train_example[\"feat_dynamic_real\"][-num_of_samples:],\n",
    "          color=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b802b9b3-0a9e-4546-96e0-61c1a8dda3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(10_000)\n",
    "def convert_to_pandas_period(date, freq):\n",
    "    return pd.Period(date, freq)\n",
    "\n",
    "\n",
    "def transform_start_field(batch, freq):\n",
    "    batch[\"start\"] = [convert_to_pandas_period(date, freq) for date in batch[\"start\"]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "600028d7-a2a4-4d8f-905f-168eaa2dee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_transform(partial(transform_start_field, freq=freq))\n",
    "# test_dataset.set_transform(partial(transform_start_field, freq=freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "642a647f-d53b-481f-8704-8f97470198f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_variates = len(train_dataset)\n",
    "\n",
    "train_grouper = MultivariateGrouper(max_target_dim=num_of_variates)\n",
    "# test_grouper = MultivariateGrouper(\n",
    "#     max_target_dim=num_of_variates,\n",
    "#     num_test_dates= None, # len(test_dataset)\n",
    "#     num_of_variates  # number of rolling test windows\n",
    "# )\n",
    "\n",
    "multi_variate_train_dataset = train_grouper(train_dataset)\n",
    "# multi_variate_test_dataset = test_grouper(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3223c9fe-093b-4096-ba82-70f28113d546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_variate_train_example['target'].shape = (266, 99)\n"
     ]
    }
   ],
   "source": [
    "multi_variate_train_example = multi_variate_train_dataset[0]\n",
    "print(\n",
    "    f\"multi_variate_train_example['target'].shape = {multi_variate_train_example['target'].shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cee8848f-3d3a-420b-a1f7-a4670d69f638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function day_of_month at 0x12d65d3a0>, <function week_of_year at 0x12d65d760>]\n"
     ]
    }
   ],
   "source": [
    "from gluonts.time_feature import time_features_from_frequency_str\n",
    "\n",
    "time_features = time_features_from_frequency_str(freq)\n",
    "print(time_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f00bb-84b5-43a4-89d0-2cff2ef6d876",
   "metadata": {},
   "source": [
    "Look back certain time range for each time step, as additional features \"lags_sequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e902b76c-6b1c-4852-b35c-626e4659f32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 12, 51, 52, 53, 103, 104, 105, 155, 156, 157]\n"
     ]
    }
   ],
   "source": [
    "lags_sequence = get_lags_for_frequency(freq)\n",
    "print(lags_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e1358e5-92af-46e8-8366-08a865067125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'day_of_month': array([-0.36666667]), 'week_of_year': array([-0.5])}\n"
     ]
    }
   ],
   "source": [
    "timestamp = pd.Period(\"2025-01-01 01:00:01\", freq=freq)\n",
    "timestamp_as_index = pd.PeriodIndex(data=period_array([timestamp]))\n",
    "additional_features = [\n",
    "    (time_feature.__name__, time_feature(timestamp_as_index))\n",
    "    for time_feature in time_features\n",
    "]\n",
    "print(dict(additional_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec7e5895-9d89-4148-a8c3-ed1bebf783d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = InformerConfig(\n",
    "    # in the multivariate setting, input_size is the number of variates in the time series per time step\n",
    "    input_size=num_of_variates,\n",
    "    # prediction length:\n",
    "    prediction_length=prediction_length,\n",
    "    # context length:\n",
    "    context_length=prediction_length * 2,\n",
    "    # lags value copied from 1 week before:\n",
    "    lags_sequence=[1, 24 * 7],\n",
    "    # we'll add 5 time features (\"hour_of_day\", ..., and \"age\"):\n",
    "    num_time_features=len(time_features) + 1,\n",
    "    # informer params:\n",
    "    dropout=0.1,\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=4,\n",
    "    # project input from num_of_variates*len(lags_sequence)+num_time_features to:\n",
    "    d_model=64,\n",
    ")\n",
    "\n",
    "model = InformerForPrediction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e18bb22-004f-4176-9c4b-3051b6226d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'student_t'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.distribution_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b2265052-836a-4131-b12c-2df354ad9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n",
    "    # create list of fields to remove later\n",
    "    remove_field_names = []\n",
    "    if config.num_static_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
    "    if config.num_dynamic_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
    "    if config.num_static_categorical_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_CAT)\n",
    "\n",
    "    return Chain(\n",
    "        # step 1: remove static/dynamic fields if not specified\n",
    "        [RemoveFields(field_names=remove_field_names)]\n",
    "        # step 2: convert the data to NumPy (potentially not needed)\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_CAT,\n",
    "                    expected_ndim=1,\n",
    "                    dtype=int,\n",
    "                )\n",
    "            ]\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else []\n",
    "        )\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_REAL,\n",
    "                    expected_ndim=1,\n",
    "                )\n",
    "            ]\n",
    "            if config.num_static_real_features > 0\n",
    "            else []\n",
    "        )\n",
    "        + [\n",
    "            AsNumpyArray(\n",
    "                field=FieldName.TARGET,\n",
    "                # we expect an extra dim for the multivariate case:\n",
    "                expected_ndim=1 if config.input_size == 1 else 2,\n",
    "            ),\n",
    "            # step 3: handle the NaN's by filling in the target with zero\n",
    "            # and return the mask (which is in the observed values)\n",
    "            # true for observed values, false for nan's\n",
    "            # the decoder uses this mask (no loss is incurred for unobserved values)\n",
    "            # see loss_weights inside the xxxForPrediction model\n",
    "            AddObservedValuesIndicator(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.OBSERVED_VALUES,\n",
    "            ),\n",
    "            # step 4: add temporal features based on freq of the dataset\n",
    "            # these serve as positional encodings\n",
    "            AddTimeFeatures(\n",
    "                start_field=FieldName.START,\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                time_features=time_features_from_frequency_str(freq),\n",
    "                pred_length=config.prediction_length,\n",
    "            ),\n",
    "            # step 5: add another temporal feature (just a single number)\n",
    "            # tells the model where in the life the value of the time series is\n",
    "            # sort of running counter\n",
    "            AddAgeFeature(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_AGE,\n",
    "                pred_length=config.prediction_length,\n",
    "                log_scale=True,\n",
    "            ),\n",
    "            # step 6: vertically stack all the temporal features into the key FEAT_TIME\n",
    "            VstackFeatures(\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
    "                + (\n",
    "                    [FieldName.FEAT_DYNAMIC_REAL]\n",
    "                    if config.num_dynamic_real_features > 0\n",
    "                    else []\n",
    "                ),\n",
    "            ),\n",
    "            # step 7: rename to match HuggingFace names\n",
    "            RenameFields(\n",
    "                mapping={\n",
    "                    FieldName.FEAT_STATIC_CAT: \"static_categorical_features\",\n",
    "                    FieldName.FEAT_STATIC_REAL: \"static_real_features\",\n",
    "                    FieldName.FEAT_TIME: \"time_features\",\n",
    "                    FieldName.TARGET: \"values\",\n",
    "                    FieldName.OBSERVED_VALUES: \"observed_mask\",\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8850e0d-a330-4d7a-a528-c6cfb7e0ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instance_splitter(\n",
    "    config: PretrainedConfig,\n",
    "    mode: str,\n",
    "    train_sampler: Optional[InstanceSampler] = None,\n",
    "    validation_sampler: Optional[InstanceSampler] = None,\n",
    ") -> Transformation:\n",
    "    assert mode in [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "    instance_sampler = {\n",
    "        \"train\": train_sampler\n",
    "        or ExpectedNumInstanceSampler(\n",
    "            num_instances=1.0, min_future=config.prediction_length\n",
    "        ),\n",
    "        \"validation\": validation_sampler\n",
    "        or ValidationSplitSampler(min_future=config.prediction_length),\n",
    "        \"test\": TestSplitSampler(),\n",
    "    }[mode]\n",
    "\n",
    "    return InstanceSplitter(\n",
    "        target_field=\"values\",\n",
    "        is_pad_field=FieldName.IS_PAD,\n",
    "        start_field=FieldName.START,\n",
    "        forecast_start_field=FieldName.FORECAST_START,\n",
    "        instance_sampler=instance_sampler,\n",
    "        past_length=config.context_length + max(config.lags_sequence),\n",
    "        future_length=config.prediction_length,\n",
    "        time_series_fields=[\"time_features\", \"observed_mask\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3167024f-4064-496b-b442-12d5a80b40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from gluonts.itertools import Cached, Cyclic\n",
    "from gluonts.dataset.loader import as_stacked_batches\n",
    "\n",
    "\n",
    "def create_train_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    num_batches_per_epoch: int,\n",
    "    shuffle_buffer_length: Optional[int] = None,\n",
    "    cache_data: bool = True,\n",
    "    **kwargs,\n",
    ") -> Iterable:\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
    "        \"future_values\",\n",
    "        \"future_observed_mask\",\n",
    "    ]\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=True)\n",
    "    if cache_data:\n",
    "        transformed_data = Cached(transformed_data)\n",
    "\n",
    "    # we initialize a Training instance\n",
    "    instance_splitter = create_instance_splitter(config, \"train\")\n",
    "\n",
    "    # the instance splitter will sample a window of\n",
    "    # context length + lags + prediction length (from all the possible transformed time series, 1 in our case)\n",
    "    # randomly from within the target time series and return an iterator.\n",
    "    stream = Cyclic(transformed_data).stream()\n",
    "    training_instances = instance_splitter.apply(stream)\n",
    "\n",
    "    return as_stacked_batches(\n",
    "        training_instances,\n",
    "        batch_size=batch_size,\n",
    "        shuffle_buffer_length=shuffle_buffer_length,\n",
    "        field_names=TRAINING_INPUT_NAMES,\n",
    "        output_type=torch.tensor,\n",
    "        num_batches_per_epoch=num_batches_per_epoch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1d9e0668-ceac-47a7-9ecf-fa7868267258",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_train_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=multi_variate_train_dataset,\n",
    "    batch_size=256,\n",
    "    num_batches_per_epoch=100,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c51f58dc-21f6-4c05-9da8-cd726eeeb4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_time_features torch.Size([256, 184, 3]) torch.FloatTensor\n",
      "past_values torch.Size([256, 184, 266]) torch.FloatTensor\n",
      "past_observed_mask torch.Size([256, 184, 266]) torch.FloatTensor\n",
      "future_time_features torch.Size([256, 8, 3]) torch.FloatTensor\n",
      "future_values torch.Size([256, 8, 266]) torch.FloatTensor\n",
      "future_observed_mask torch.Size([256, 8, 266]) torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed0c81f1-8d8a-4f94-b34a-5718e79293c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 : 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     23\u001b[39m outputs = model(\n\u001b[32m     24\u001b[39m     static_categorical_features=batch[\u001b[33m\"\u001b[39m\u001b[33mstatic_categorical_features\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.num_static_categorical_features > \u001b[32m0\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     future_observed_mask=batch[\u001b[33m\"\u001b[39m\u001b[33mfuture_observed_mask\u001b[39m\u001b[33m\"\u001b[39m].to(device),\n\u001b[32m     36\u001b[39m )\n\u001b[32m     37\u001b[39m loss = outputs.loss\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m progress_bar.set_postfix(loss=\u001b[43mtotal_loss\u001b[49m / (progress_bar.n + \u001b[32m1\u001b[39m))\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[32m     42\u001b[39m accelerator.backward(loss)\n",
      "\u001b[31mNameError\u001b[39m: name 'total_loss' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 150\n",
    "loss_history = []\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=6e-5, betas=(0.9, 0.95), weight_decay=1e-1)\n",
    "\n",
    "model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs} \")\n",
    "    # for data in tqdm(train_dataloader,  desc=f\"Epoch {epoch+1}\"):   \n",
    "    for idx, batch in enumerate(progress_bar):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else None,\n",
    "            static_real_features=batch[\"static_real_features\"].to(device)\n",
    "            if config.num_static_real_features > 0\n",
    "            else None,\n",
    "            past_time_features=batch[\"past_time_features\"].to(device),\n",
    "            past_values=batch[\"past_values\"].to(device),\n",
    "            future_time_features=batch[\"future_time_features\"].to(device),\n",
    "            future_values=batch[\"future_values\"].to(device),\n",
    "            past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "            future_observed_mask=batch[\"future_observed_mask\"].to(device),\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=total_loss / (progress_bar.n + 1))\n",
    "\n",
    "        # Backpropagation\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "        if idx % 200 == 0:\n",
    "            print(f'Epoch {epoch} & idx {idx} with loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07c300-e02d-4e26-9359-1de2b5db2f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
