{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa90e46-2b63-4c0c-b210-f5e09e43b4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: huggingface_hub in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (0.32.4)\n",
      "Requirement already satisfied: fsspec in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (2025.3.0)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: packaging in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from huggingface_hub) (1.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rckyi/miniforge3/envs/gpu_py311/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets huggingface_hub fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5924fcdf-2164-4c24-94bd-e0a523b249e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from chronos import BaseChronosPipeline, ChronosTokenizer\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "# from torch.utils.data import DataLoader\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, pipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq\n",
    "import accelerate\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33882b8b-7fc5-42e7-acfd-cd4c50f70802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return cls(\n",
    "#             tokenizer=chronos_config.create_tokenizer(),\n",
    "#             model=ChronosModel(config=chronos_config, model=inner_model),\n",
    "#         )\n",
    "\n",
    "\n",
    "pipeline = BaseChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",  # use \"amazon/chronos-bolt-small\" for the corresponding Chronos-Bolt model\n",
    "    device_map=\"auto\",  # use \"cpu\" for CPU inference\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d36e000-5839-4b23-b603-df202ece6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.model.to(torch.device(\"mps\"))\n",
    "tokenizer = pipeline.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9063c0-a497-4f14-9c0c-4d9b08856dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e73994-d7b4-41b9-80a2-6f8d3efd6b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "dataset = load_dataset(\"shaddie/thrust_curves_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847cdc16-08d1-450d-bedd-71c2c786e315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['time', 'thrust', 'motorId', 'motor_name', 'impulse_class', 'id'],\n",
       "        num_rows: 6008\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d831e9d-1c3b-454f-a8bc-d529d6ef7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_windows(values, context_length, prediction_length):\n",
    "    inputs, targets = [], []\n",
    "    total_length = context_length + prediction_length\n",
    "    for i in range(len(values) - total_length + 1):\n",
    "        context = values[i : i + context_length]\n",
    "        target = values[i + context_length : i + total_length]\n",
    "        inputs.append(context)\n",
    "        targets.append(target)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f499a115-229a-419f-bac0-ce8080d5df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "\n",
    "context_length = 24\n",
    "prediction_length = 12\n",
    "\n",
    "# Step 1: Group values by 'motorId'\n",
    "groups = defaultdict(list)\n",
    "for example in dataset['train']:\n",
    "    id = example['id']\n",
    "    time = example['time']\n",
    "    motor_id = example['motorId']\n",
    "    value = example['thrust']\n",
    "    impulse_class = example['impulse_class']\n",
    "    groups[motor_id].append({'id': id, 'time': time, 'thrust': value, 'motor_id': motor_id, 'impulse_class': impulse_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f33dd80-b960-444e-890c-1b1d266f9da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'time': 0.0,\n",
       "  'thrust': 0.0,\n",
       "  'motor_id': '5f4294d200023100000000f7',\n",
       "  'impulse_class': 'J'},\n",
       " {'id': 1,\n",
       "  'time': 0.0,\n",
       "  'thrust': 1.0,\n",
       "  'motor_id': '5f4294d200023100000000f7',\n",
       "  'impulse_class': 'J'},\n",
       " {'id': 2,\n",
       "  'time': 0.0533667938931297,\n",
       "  'thrust': 0.800000899236099,\n",
       "  'motor_id': '5f4294d200023100000000f7',\n",
       "  'impulse_class': 'J'},\n",
       " {'id': 3,\n",
       "  'time': 0.4013167938931297,\n",
       "  'thrust': 0.6923083840277684,\n",
       "  'motor_id': '5f4294d200023100000000f7',\n",
       "  'impulse_class': 'J'},\n",
       " {'id': 4,\n",
       "  'time': 0.7876946564885495,\n",
       "  'thrust': 0.4153841311805621,\n",
       "  'motor_id': '5f4294d200023100000000f7',\n",
       "  'impulse_class': 'J'},\n",
       " {'id': 5,\n",
       "  'time': 0.8239847328244275,\n",
       "  'thrust': 0.2307687119791736,\n",
       "  'motor_id': '5f4294d200023100000000f7',\n",
       "  'impulse_class': 'J'},\n",
       " {'id': 6,\n",
       "  'time': 0.8709465648854962,\n",
       "  'thrust': 0.1538462576041652,\n",
       "  'motor_id': '5f4294d200023100000000f7',\n",
       "  'impulse_class': 'J'},\n",
       " {'id': 7,\n",
       "  'time': 1.0,\n",
       "  'thrust': 0.0,\n",
       "  'motor_id': '5f4294d200023100000000f7',\n",
       "  'impulse_class': 'J'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups['5f4294d200023100000000f7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f43fe06-07e4-4b8c-810e-9d17cd337075",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = []\n",
    "for key, value in groups.items():\n",
    "    group_keys.append({'id': [v['id'] for v in value][0] \n",
    "                       ,'time':[(v['time']) for v in value]\n",
    "                       ,'thrust':[(v['thrust']) for v in value]\n",
    "                       ,'motor_id':key\n",
    "                       ,'impulse_class': [(v['impulse_class']) for v in value][0]\n",
    "                      })\n",
    "    # print(f'key, value {key} -> {len(value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20913e73-be40-49e6-8a8a-78551685b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Slide windows within each group\n",
    "def generate_windows(values, context_length, prediction_length):\n",
    "    total_length = context_length + prediction_length\n",
    "    windows = []\n",
    "    for i in range(len(values) - total_length + 1):\n",
    "        context = values[i : i + context_length]\n",
    "        target = values[i + context_length : i + total_length]\n",
    "        windows.append((context, target))\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f2c49-e609-4f50-937a-b72b64ed6ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89a212ab-3ce0-4dff-8466-e6f2caa344bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Aggregate all windows into a flat dataset\n",
    "windowed_data = []\n",
    "for motor_id, values in groups.items():\n",
    "    windows = generate_windows(values, context_length, prediction_length)\n",
    "    # print(f'motor id {windows}')\n",
    "    for context, target in windows:\n",
    "        windowed_data.append({\n",
    "                    'input':{'id': [c['id'] for c in context][0] \n",
    "                            ,'time':[(c['time']) for c in context]\n",
    "                            ,'thrust':[(c['thrust']) for c in context]\n",
    "                            ,'motor_id':[(c['motor_id']) for c in context][0]\n",
    "                            ,'impulse_class': [(c['impulse_class']) for c in context][0]\n",
    "                            }\n",
    "                    , 'target':{'id': [t['id'] for t in target][0] \n",
    "                            ,'time':[(t['time']) for t in target]\n",
    "                            ,'thrust':[(t['thrust']) for t in target]\n",
    "                            ,'motor_id':[(t['motor_id']) for t in target][0]\n",
    "                            ,'impulse_class': [(t['impulse_class']) for t in target][0]\n",
    "                            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b48c4990-1d93-41fc-8228-037716c30d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build a Dataset\n",
    "windowed_dataset = Dataset.from_list(windowed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd9e9bc-fe59-4928-9874-57c39d9fe48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target'],\n",
       "    num_rows: 191\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a51112b6-3832-4ace-925c-c2d2c77d82d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 23,\n",
       " 'impulse_class': 'J',\n",
       " 'motor_id': '5f4294d20002310000000256',\n",
       " 'thrust': [0.0,\n",
       "  0.9454233664183034,\n",
       "  0.7429588165385054,\n",
       "  1.0,\n",
       "  0.7183106043750306,\n",
       "  0.711268064230788,\n",
       "  0.5633801479326868,\n",
       "  0.7429588165385054,\n",
       "  0.8327467941586668,\n",
       "  0.7376758939182626,\n",
       "  0.7235921703125255,\n",
       "  0.7411978423317578,\n",
       "  0.7411978423317578,\n",
       "  0.7447184340625052,\n",
       "  0.7429588165385054,\n",
       "  0.7605631318749899,\n",
       "  0.7834517265144649,\n",
       "  0.8028170160576971,\n",
       "  0.8133801479326868,\n",
       "  0.8116205304086872,\n",
       "  0.8098595562019396,\n",
       "  0.8045779902644447,\n",
       "  0.7975354501202021,\n",
       "  0.7799297781009698],\n",
       " 'time': [0.0,\n",
       "  0.0143426294820717,\n",
       "  0.0191235059760956,\n",
       "  0.0247011952191235,\n",
       "  0.0310756972111553,\n",
       "  0.0406374501992031,\n",
       "  0.0430278884462151,\n",
       "  0.050199203187251,\n",
       "  0.0629482071713147,\n",
       "  0.0749003984063745,\n",
       "  0.0844621513944223,\n",
       "  0.1011952191235059,\n",
       "  0.1163346613545816,\n",
       "  0.1521912350597609,\n",
       "  0.2231075697211156,\n",
       "  0.30199203187251,\n",
       "  0.3768924302788844,\n",
       "  0.4446215139442231,\n",
       "  0.5011952191235061,\n",
       "  0.5490039840637451,\n",
       "  0.6270916334661355,\n",
       "  0.6589641434262948,\n",
       "  0.7107569721115539,\n",
       "  0.754581673306773]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowed_dataset['input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f119020e-c51c-4830-aa1c-671284774753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windowed_dataset['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83d4cf4e-459c-4c76-83b0-b70ade567662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057fe6a8bb4742cdbbea092bc4b13392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/191 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_windowed(example):\n",
    "    # Include motorId in input prompt if helpful (optional)\n",
    "    # input_str = f\"forecast: \" + \" \".join(map(str, example[\"input\"]))\n",
    "    # target_str = \" \".join(map(str, example[\"target\"]))\n",
    "    # print(example['input']['thrust'])\n",
    "    t = torch.from_numpy(np.asarray(example['input']['thrust']))\n",
    "    t_shape = t.shape\n",
    "    t = t.reshape(1, t_shape[0])\n",
    "    # print(t.shape)\n",
    "\n",
    "    token_ids, attention_mask, scale = tokenizer.context_input_transform(t)\n",
    "    token_ids, attention_mask = tokenizer._append_eos_token(token_ids, attention_mask)\n",
    "    \n",
    "    # tokenizer.pad_token = tokenizer.eos_token\n",
    "    return {\n",
    "            \"token_ids\": token_ids\n",
    "            , \"attention_mask\": attention_mask\n",
    "            , \"scale\": scale\n",
    "    }\n",
    "\n",
    "tokenized_dataset = windowed_dataset.map(preprocess_windowed, remove_columns=windowed_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91dc39c6-10da-4efc-a304-9f43c6d8f8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['token_ids', 'attention_mask', 'scale'],\n",
       "    num_rows: 191\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f06700fc-6919-4ed4-94d7-f17e8c136166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_windowed(example):\n",
    "    input_str = \"forecast: \" + \" \".join(map(str, example[\"token_ids\"]))\n",
    "    # target_str = \" \".join(map(str, example[\"target\"]))\n",
    "    return tokenizer.context_input_transform(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec145027-0f8b-4092-bf91-34c5c68459d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08044f786a8b45f692982a07fb73109f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/191 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m prep_tokenized_dataset = \u001b[43mtokenized_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_windowed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/datasets/arrow_dataset.py:3079\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[39m\n\u001b[32m   3073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3074\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[32m   3075\u001b[39m         unit=\u001b[33m\"\u001b[39m\u001b[33m examples\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3076\u001b[39m         total=pbar_total,\n\u001b[32m   3077\u001b[39m         desc=desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3078\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m3079\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/datasets/arrow_dataset.py:3501\u001b[39m, in \u001b[36mDataset._map_single\u001b[39m\u001b[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[39m\n\u001b[32m   3499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[32m   3500\u001b[39m     _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3501\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3502\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3503\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/datasets/arrow_dataset.py:3475\u001b[39m, in \u001b[36mDataset._map_single.<locals>.iter_outputs\u001b[39m\u001b[34m(shard_iterable)\u001b[39m\n\u001b[32m   3473\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3474\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[32m-> \u001b[39m\u001b[32m3475\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/datasets/arrow_dataset.py:3398\u001b[39m, in \u001b[36mDataset._map_single.<locals>.apply_function\u001b[39m\u001b[34m(pa_inputs, indices, offset)\u001b[39m\n\u001b[32m   3396\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[32m   3397\u001b[39m inputs, fn_args, additional_args, fn_kwargs = prepare_inputs(pa_inputs, indices, offset=offset)\n\u001b[32m-> \u001b[39m\u001b[32m3398\u001b[39m processed_inputs = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3399\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mpreprocess_windowed\u001b[39m\u001b[34m(example)\u001b[39m\n\u001b[32m      2\u001b[39m input_str = \u001b[33m\"\u001b[39m\u001b[33mforecast: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, example[\u001b[33m\"\u001b[39m\u001b[33mtoken_ids\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# target_str = \" \".join(map(str, example[\"target\"]))\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontext_input_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/chronos-forecasting/src/chronos/chronos.py:219\u001b[39m, in \u001b[36mMeanScaleUniformBins.context_input_transform\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontext_input_transform\u001b[39m(\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m, context: torch.Tensor\n\u001b[32m    218\u001b[39m ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     length = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m[-\u001b[32m1\u001b[39m]\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m length > \u001b[38;5;28mself\u001b[39m.config.context_length:\n\u001b[32m    222\u001b[39m         context = context[..., -\u001b[38;5;28mself\u001b[39m.config.context_length :]\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "prep_tokenized_dataset = tokenized_dataset.map(preprocess_windowed, remove_columns=tokenized_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1aec6ce3-7f44-426a-9eee-c12c0514649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "667ff560-687c-4929-b080-c291f6fdf200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "work_dir = os.getcwd()\n",
    "model_dir = os.getcwd().replace('GitHub/chronos-forecasting','DL_Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ff08bcd-b94d-412a-8303-2c993e079f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    fp16=torch.cuda.is_bf16_supported(),\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d240a71-65c3-45c6-bac2-b3160d8f4464",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_collator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m trainer = Trainer(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     args=training_args,\n\u001b[32m      4\u001b[39m     train_dataset=tokenized_dataset,\n\u001b[32m      5\u001b[39m     tokenizer=tokenizer,\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     data_collator=\u001b[43mdata_collator\u001b[49m,\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'data_collator' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1afa8ac6-13e4-4c57-ae2d-0feb7542782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, examples, tokenizer):\n",
    "        self.examples = examples  # ✅ renamed from 'data'\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        input_str = f\"forecast: {' '.join(map(str, example['input']))}\"\n",
    "        target_str = \" \".join(map(str, example[\"target\"]))\n",
    "\n",
    "        tokenized = self.tokenizer(\n",
    "            input_str,\n",
    "            text_target=target_str,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": tokenized[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": tokenized[\"labels\"].squeeze()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5615b130-77d5-4298-87fb-07ad1dda5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Train\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21e6ab24-8537-4154-be16-27165328475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a PyTorch Dataset\n",
    "# class TimeSeriesDataset(Dataset):\n",
    "#     def __init__(self, data, tokenizer):\n",
    "#         self.data = data\n",
    "#         self.tokenizer = tokenizer\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         example = self.data[idx]\n",
    "#         input_str = f\"forecast: {' '.join(map(str, example['input']))}\"\n",
    "#         target_str = \" \".join(map(str, example[\"target\"]))\n",
    "\n",
    "#         tokenized = self.tokenizer(\n",
    "#             input_str,\n",
    "#             text_target=target_str,\n",
    "#             truncation=True,\n",
    "#             padding=\"max_length\",\n",
    "#             max_length=128,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "\n",
    "#         # Squeeze to remove batch dimension\n",
    "#         return {\n",
    "#             \"input_ids\": tokenized[\"input_ids\"].squeeze(),\n",
    "#             \"attention_mask\": tokenized[\"attention_mask\"].squeeze(),\n",
    "#             \"labels\": tokenized[\"labels\"].squeeze()\n",
    "#         }\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TimeSeriesDataset(windowed_dataset, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2221276f-7c2a-4fc3-a816-2ca0f0cbabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## copied from https://github.com/amazon-science/chronos-forecasting/blob/main/scripts/training/train.py\n",
    "# def __init__(\n",
    "#         self,\n",
    "#         datasets: list,\n",
    "#         probabilities: List[float],\n",
    "#         tokenizer: ChronosTokenizer,\n",
    "#         context_length: int = 512,\n",
    "#         prediction_length: int = 64,\n",
    "#         drop_prob: float = 0.2,\n",
    "#         min_past: Optional[int] = None,\n",
    "#         model_type: str = \"seq2seq\",\n",
    "#         imputation_method: Optional[MissingValueImputation] = None,\n",
    "#         mode: str = \"training\",\n",
    "#         np_dtype=np.float32,\n",
    "\n",
    "\n",
    "\n",
    "def to_hf_format(entry: dict, tokenizer: ChronosTokenizer, model_type: str) -> dict:\n",
    "        print((entry[\"target\"]))\n",
    "        past_target = torch.from_numpy(np.asarray(entry[\"input\"][\"thrust\"])).unsqueeze(0)\n",
    "        \n",
    "        input_ids, attention_mask, scale = tokenizer.context_input_transform(\n",
    "            past_target\n",
    "        )\n",
    "        print(f'scale {scale}')\n",
    "        future_target = torch.tensor(entry[\"target\"][\"thrust\"]).unsqueeze(0)\n",
    "        print(f'shape past target {future_target.shape} {future_target.shape[-1]}')\n",
    "        labels, labels_mask = tokenizer.label_input_transform(future_target, scale)\n",
    "        labels[labels_mask == 0] = -100\n",
    "\n",
    "        if model_type == \"causal\":\n",
    "            # The InstanceSplitter pads time series on the left to be equal to the\n",
    "            # context_length. However, certain models (e.g., GPT2) with absolute\n",
    "            # position embeddings should not be trained with left padding.\n",
    "            # The following piece of code moves padding from left to right.\n",
    "\n",
    "            assert input_ids.shape[-1] == entry[\"past_is_pad\"].shape[0]\n",
    "\n",
    "            # Find the index where padding starts\n",
    "            pad_start_idx = np.searchsorted(1 - entry[\"past_is_pad\"], 1)\n",
    "            padded_input_ids, obs_input_ids = torch.tensor_split(\n",
    "                input_ids, [pad_start_idx], dim=-1\n",
    "            )\n",
    "            padded_attention_mask, obs_attention_mask = torch.tensor_split(\n",
    "                attention_mask, [pad_start_idx], dim=-1\n",
    "            )\n",
    "\n",
    "            # Move padding to the right\n",
    "            input_ids = torch.cat(\n",
    "                [\n",
    "                    obs_input_ids,\n",
    "                    labels,\n",
    "                    padded_input_ids,\n",
    "                ],\n",
    "                axis=-1,\n",
    "            )\n",
    "            attention_mask = torch.cat(\n",
    "                [\n",
    "                    obs_attention_mask,\n",
    "                    labels_mask,\n",
    "                    padded_attention_mask,\n",
    "                ],\n",
    "                axis=-1,\n",
    "            )\n",
    "\n",
    "            # labels for causal models are same as the input_ids.\n",
    "            # Internally transformers shifts the labels by one during training.\n",
    "            labels = input_ids.clone()\n",
    "            input_ids[~attention_mask] = self.tokenizer.config.pad_token_id\n",
    "            labels[~attention_mask] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids.squeeze(0),\n",
    "            \"attention_mask\": attention_mask.squeeze(0),\n",
    "            \"labels\": labels.squeeze(0),\n",
    "        }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f942a0e9-9422-453f-b0f7-d83571ca965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.config.prediction_length=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "62677acb-7d47-4bf8-ab24-fc4bed02564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 48, 'impulse_class': 'J', 'motor_id': '5f4294d20002310000000256', 'thrust': [0.7816907523077173, 0.7904929099759597, 0.7904929099759597, 0.75, 0.6021134403846466, 0.4489439581490506, 0.3732397041346263, 0.3450709002404041, 0.3045779902644446, 0.1830992603365658, 0.105634032115394, 0.0440135017067069], 'time': [0.7944223107569722, 0.8087649402390438, 0.8175298804780877, 0.8278884462151395, 0.851792828685259, 0.8764940239043826, 0.8924302788844624, 0.9123505976095618, 0.9250996015936256, 0.9505976095617532, 0.9633466135458169, 0.9776892430278886]}\n",
      "scale tensor([0.7762])\n",
      "shape past target torch.Size([1, 12]) 12\n"
     ]
    }
   ],
   "source": [
    "hf_format_dataset = to_hf_format(windowed_dataset[1], tokenizer, \"seq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4a4bca9c-e845-4639-aab2-eed8ee955fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([2215, 2180, 2225, 2175, 2174, 2148, 2180, 2195, 2179, 2176, 2179, 2179,\n",
       "         2180, 2180, 2183, 2187, 2190, 2192, 2192, 2191, 2190, 2189, 2186, 2185,\n",
       "            1]),\n",
       " 'attention_mask': tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True]),\n",
       " 'labels': tensor([2186, 2188, 2188, 2181, 2155, 2128, 2115, 2110, 2103, 2081, 2068, 2057,\n",
       "            1])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_format_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "48c6449f-42f8-44d1-a316-8ce87474eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    fp16=torch.cuda.is_bf16_supported(),\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bc0b1a1-d5fa-4ca5-bcb0-68601c261a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/m6srhcs95fjf3ng4s8q9tj6h0000gn/T/ipykernel_8282/292052052.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_format_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "909fd854-edfc-4ecc-a8cd-b52ac248e2c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/transformers/trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/transformers/trainer.py:2509\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2507\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2508\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2509\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2510\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2511\u001b[39m     step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/transformers/trainer.py:5263\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5261\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5262\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5263\u001b[39m         batch_samples.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   5264\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5265\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/accelerate/data_loader.py:566\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     current_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b99f05f1-5da5-4fbd-b48f-78011dac0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87a106c5-50b5-4583-9e83-e8a7e7b426af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "\n",
    "optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
    "lr_scheduler = AdafactorSchedule(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c39c9c38-835d-4249-aec4-c960fbbb2e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                                                                                                          | 0/12 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'MeanScaleUniformBins' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      6\u001b[39m     total_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/datasets/arrow_dataset.py:2781\u001b[39m, in \u001b[36mDataset.__getitems__\u001b[39m\u001b[34m(self, keys)\u001b[39m\n\u001b[32m   2779\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: \u001b[38;5;28mlist\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m   2780\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2781\u001b[39m     batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2782\u001b[39m     n_examples = \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[32m   2783\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch.items()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mTimeSeriesDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     11\u001b[39m input_str = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforecast: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39mexample[\u001b[33m'\u001b[39m\u001b[33minput\u001b[39m\u001b[33m'\u001b[39m]))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m target_str = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, example[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m tokenized = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_target\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_length\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m: tokenized[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].squeeze(),\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m: tokenized[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m].squeeze(),\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m: tokenized[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m].squeeze()\n\u001b[32m     27\u001b[39m }\n",
      "\u001b[31mTypeError\u001b[39m: 'MeanScaleUniformBins' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Training Loop\n",
    "# epochs = 3\n",
    "# model.train()\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     total_loss = 0.0\n",
    "#     for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "#         outputs = model(**batch)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef31c1-720f-41b6-8c1b-519f955d4222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
